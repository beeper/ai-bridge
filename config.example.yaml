# Example configuration for the ai-bridge OpenAI Matrix bridge.

homeserver:
  address: https://matrix-client.example.com
  domain: example.com
  verify_ssl: true
  async_media: true

appservice:
  address: http://localhost:29345
  hostname: 0.0.0.0
  port: 29345
  database: openai-bridge.db
  id: openai-gpt
  bot:
    username: gptbridge
    displayname: "ChatGPT Bridge"
    # avatar: mxc://example.com/abcdef
  as_token: "GENERATE-A-TOKEN"
  hs_token: "GENERATE-A-TOKEN"

logging:
  level: info
  format: json

database:
  type: sqlite3
  uri: file:openai-bridge.db?_pragma=busy_timeout=5000

metrics:
  enabled: true
  listen: 0.0.0.0:9000

bridge:
  command_prefix: "!gpt"
  sync_with_custom_puppets: false

encryption:
  allow: true
  default: false

# Connector-specific options (identical to pkg/connector/example-config.yaml)
network:
  openai:
    api_key: ""
    organization_id: ""
    project_id: ""
    base_url: ""
    default_model: "gpt-4.1-mini"
    default_temperature: 0.3
    max_context_messages: 12
    max_completion_tokens: 512
    system_prompt: |
      You are a helpful assistant talking to Matrix users via the ai-bridge.
      Answer clearly and concisely.
    request_timeout: 45s
  bridge:
    command_prefix: "!gpt"
    typing_notifications: true
    mention_assistant: false
