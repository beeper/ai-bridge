# Example configuration for the ai-bridge OpenAI Matrix bridge.

homeserver:
  address: https://matrix-client.example.com
  domain: example.com
  verify_ssl: true
  async_media: true

appservice:
  address: http://localhost:29345
  hostname: 0.0.0.0
  port: 29345
  database: openai-bridge.db
  id: openai-gpt
  bot:
    username: gptbridge
    displayname: "ChatGPT Bridge"
    # avatar: mxc://example.com/abcdef
  as_token: "GENERATE-A-TOKEN"
  hs_token: "GENERATE-A-TOKEN"

logging:
  level: info
  format: json

database:
  type: sqlite3
  uri: file:openai-bridge.db?_pragma=busy_timeout=5000

metrics:
  enabled: true
  listen: 0.0.0.0:9000

bridge:
  command_prefix: "!ai"
  sync_with_custom_puppets: false

encryption:
  allow: true
  default: false

# Connector-specific options (identical to pkg/connector/example-config.yaml)
network:
  # Beeper AI credentials for automatic login (optional)
  beeper:
    base_url: ""  # Required if using Beeper provider
    token: ""

  # Per-provider default models
  providers:
    beeper:
      default_model: "openai/gpt-5.2"
    openai:
      default_model: "openai/gpt-4o-mini"
    gemini:
      default_model: "gemini/gemini-2.5-flash"
    anthropic:
      default_model: "anthropic/claude-sonnet-4-5-20250929"
    openrouter:
      default_model: "openrouter/openai/gpt-4o-mini"
      # Optional OpenRouter app attribution headers.
      # Defaults: https://beeper.com / Beeper
      # app_referer: "https://example.com"
      # app_title: "My Matrix AI Bridge"

  # Global settings
  default_system_prompt: |
    You are a helpful assistant.
  model_cache_duration: 6h

  bridge:
    command_prefix: "!ai"
